<?xml version="1.0" encoding="utf-8"?>
<article xmlns="http://docbook.org/ns/docbook"
	 xmlns:xl="http://www.w3.org/1999/xlink"
	 version="5.0" xml:lang="en">
<info>
    <title>JLIFF, Creating a JSON Serialization of OASIS XLIFF</title>
    <subtitle>Lossless exchange between asynchronous XML based and real time JSON based
      pipelines</subtitle>
    <author>
      <personname>David Filip</personname>
      <email>david.filip@adaptcentre.ie</email>
      <uri>https://linkedin.com/in/davidfatdavidf</uri>
      <personblurb>
        <para><emphasis role="bold">David Filip</emphasis> is Chair of OASIS XLIFF OMOS TC;
          Secretary, Editor and Liaison Officer of OASIS XLIFF TC; a former Co-Chair and Editor for
          the W3C ITS 2.0 Recommendation; Convenor, JTC 1/SG 1 Open Source Software, Convenor, JTC
          1/SC 42/WG 3 Trustworthiness of AI; National mirror chair, NSAI TC 02/SC 18 AI; Head of
          the Irish national delegation, ISO/IEC JTC 1/SC 42 AI; NSAI expert to ISO/IEC JTC 1/SC 38
          Cloud Computing, ISO TC 37/SC 3 Terminology management, SC 4 Language resources, SC 5
          Language technology. His specialties include open standards and process metadata, workflow
          and meta-workflow automation. David works as a Moravia Research Fellow at the ADAPT
          Research Centre, Trinity College Dublin, Ireland. Before 2011, he oversaw key research and
          change projects for Moravia’s worldwide operations. David held research scholarships at
          universities in Vienna, Hamburg and Geneva, and graduated in 2004 from Brno University
          with a Ph.D. in Analytic Philosophy. David also holds master’s degrees in Philosophy, Art
          History, Theory of Art and German Philology.</para>
      </personblurb>
      <affiliation>
        <jobtitle>Research Fellow</jobtitle>
        <orgname>ADAPT Centre at Trinity College Dublin</orgname>
      </affiliation>
    </author>
    <author>
      <personname>Phil Ritchie</personname>
      <email>phil.ritchie@vistatec.com</email>
      <uri>http://www.vistatec.com</uri>
      <uri>http://blog.phil-ritchie.net/idiomatic-prose</uri>
      <personblurb>
        <para><emphasis role="bold">Phil Ritchie</emphasis>is Chief Technology Officer at Vistatec,
          a Dublin headquartered Language Service Provider where he directs all Research,
          Development and Process Innovation activities. He is a founding industrial partner of the
          ADAPT Research Centre and Chair of the W3C Internationalization Tag Set Interest Group.
          Phil participates in many industry groups such as the OASIS XLIFF Object Model and Other
          Serializations Technical Committee and is lead architect of the Ocelot and JliffGraphTools
          open source projects.</para>
      </personblurb>
      <affiliation>
        <jobtitle>CTO</jobtitle>
        <orgname>Vistatec</orgname>
      </affiliation>
    </author>
    <author>
      <personname>Robert van Engelen</personname>
      <email>engelen@genivia.com</email>
      <uri>https://www.linkedin.com/in/robertvanengelen</uri>
      <personblurb>
        <para><emphasis role="bold">Robert van Engelen</emphasis> is Chief Executive Officer and
          Chief Technology Officer at Genivia Inc, a Web Services development middleware provider
          and consultancy company with locations in New York, New York, and Tallahassee, Florida,
          where he directs all Research and Development. He is founding partner of Genivia (founded
          2003) and a tenured full Professor of Computer Science at the Florida State University.
          Robert specializes in Web protocols and networking technologies, compilers and software
          development tools, and machine learning. He served as Associate Editor of IEEE
          Transactions on Services Computing and has authored over 70 peer-reviewed publications.
          Robert received his Ph.D. in Computer Science in 1998 from Leiden University, the
          Netherlands, and a Master's degree in Computer Science in 1994 from Utrecht University,
          the Netherlands.</para>
      </personblurb>
      <affiliation>
        <jobtitle>CTO</jobtitle>
        <orgname>Genivia</orgname>
      </affiliation>
    </author>
    <keywordset>
      <keyword>inline data model</keyword>
      <keyword>UML</keyword>
      <keyword>JLIFF</keyword>
      <keyword>JSON</keyword>
      <keyword>JSON-LD</keyword>
      <keyword>W3C ITS</keyword>
      <keyword>XLIFF</keyword>
      <keyword>Internationalization</keyword>
      <keyword>I18n</keyword>
      <keyword>Localization</keyword>
      <keyword>L10n</keyword>
      <keyword>metadata</keyword>
      <keyword>multi-namespace</keyword>
      <keyword>namespaces</keyword>
      <keyword>mapping</keyword>
      <keyword>roundtrip</keyword>
      <keyword>lifecycle</keyword>
      <keyword>multilingual content</keyword>
    </keywordset>
    <abstract>
      <para><emphasis>JLIFF</emphasis>
        <citation>JLIFF</citation> is the JSON serialization of XLIFF. Currently JLIFF only exists
        as a reasonably stable JSON schema that is very close to being a full bidirectional mapping
        to both XLIFF 2 Versions. <emphasis>XLIFF</emphasis> is the XML Localization Interchange
        File Format. The current OASIS Standard version is <emphasis>XLIFF Version 2.1</emphasis>
        <citation>XLIFF21</citation>. The major new features added to <citation>XLIFF21</citation>
        compared to <emphasis>XLIFF Version 2. 0</emphasis>
        <citation>XLIFF20</citation> are the native <emphasis>W3C ITS 2.0</emphasis>
        <citation>ITS20</citation> support and the Advanced Validation feature via NVDL and
        Schematron. This paper describes how XLIFF was ported to JSON via an abstract object model.
        Challenges and design principles of transforming a multi-namespace business vocabulary into
        JSON while preserving lossless machine to machine interchange between the serializations are
        described in this paper. While we do explain about the <firstterm>Internationalization
          (I18n)</firstterm> and <firstterm>Localization (L10n)</firstterm> business specifics, we
        are also striving to provide general takeaways useful when porting XML based vocabularies
        into semantically and behaviorally interoperable JSON serializations. </para>
      <para/>
    </abstract>
  </info>

<para>This research was conducted at the ADAPT Centre, Trinity College Dublin, Ireland.</para>

  <para>The ADAPT Centre is funded under the SFI (Science Foundation Ireland) Research Centres
    Programme (Grant 13/RC/2106) and is co-funded under the European Regional Development
    Fund.</para>

<section xml:id="intro">
<title>Introduction</title>
    <para>In this paper and XML Prague presentation, we will explain about
        <emphasis>JLIFF</emphasis>
      <citation>JLIFF</citation>, the JSON serialization of XLIFF. JLIFF is designed to start with
      the 2.0 version number and bidirectional mapping for both XLIFF 2.0 and XLIFF 2.1 is being
      built in parallel in the initial version. The design is extensible to support any future XLIFF
      2.n+1 Version. The XLIFF 2 series has been designed to be backwards and forwards compatible.
      XLIFFF 2.n+1 versions can add orthogonal features such as the Advanced Validation added in
      XLIFF 2.1 or the Rendering Requirements to be added in XLIFF 2.2. All XLIFF 2.n specifications
      share the core namespace <code>urn:oasis:names:tc:xliff:document:2.0</code>.</para>
    <para>OASIS XLIFF OMOS TC only recently started developing JLIFF prose specification that should
      be released for the 1st public review by April 2019. It is however clear that the
      specification largely mimics the logical structure of the XLIFF 2 specifications. JLIFF is
      designed to mirror XLIFF including its numerous modules, albeit via the abstract object model.
      The modular design of XLIFF 2 makes critical use of XML's namespace support. Each XLIFF 2
      module has elements or attributes defined in namespaces other than the core XLIFF 2 namespace.
      This allows the involved agents (conformance application targets) to handle all and only those
      areas of XLIFF data that are relevant for their area of expertize (for instance
        <firstterm>Translation Memory</firstterm> matching, <firstterm>Terminology</firstterm>,
        <firstterm>Text Analysis</firstterm> or entity recognition, <firstterm>Size and Length
        Restrictions</firstterm>, and so on). Now, how do you handle multi-namespace in JSON that
      doesn't support namespaces? This is covered in </para>
  <para>The data formats we are describing in this paper are for managing
        <firstterm>Internationalization</firstterm> and <firstterm>Localization</firstterm> payloads
      and metadata throughout the multilingual content lifecycle. Even though corporations and
      governments routinely need to present the same, equivalent, or comparable content in various
      languages, <firstterm>multilingual content</firstterm> is usually not consumed in more than
      one language at the same time by the same end user. Typically the target audience consumes the
      content in their preferred language and if everything works well they don't even need to be
      aware that the monolingual content they consume is part of a multilingual content repository
      or a result of a <firstterm>Translation</firstterm>, <firstterm>Localization</firstterm>, or
      cultural adaptation process.</para>
    <para>Thus <firstterm>Multilingualism</firstterm> is transparent to the end user if implemented
      properly. To achieve end user transparency the corporations, governments, inter- or
      extra-national agencies need to develop and employ
      <firstterm>Internationalization</firstterm>, <firstterm>Localization</firstterm>, and
        <firstterm>Translation</firstterm> capabilities. While
        <firstterm>Internationalization</firstterm> is primarily done on a monolingual content or
      product, <firstterm>Localization</firstterm>, and <firstterm>Translation</firstterm> when done
      at a certain level of maturity -- as a repeatable process possibly aspiring to efficiencies of
      scale and automation -- requires a persistent <firstterm>Bitext</firstterm> format. Bitext in
      turn requires that <firstterm>Localizable</firstterm> or <firstterm>Translatable</firstterm>
      parts of the source or native format are <firstterm>Extracted</firstterm> into the Bitext
      format, which has provisions for storing the Translated or Localized target parts in an
      aligned way that allows for efficient and automated processing of content during the
      Localization roundtrip.</para>
    <para>Our paper presented to XML Prague 2017 <citation>3</citation> made a detailed introduction
      of XLIFF (<citation>XLIFF21prd02</citation> as the then current predecessor of
        <citation>XLIFF21</citation> backwards compatible with <citation>XLIFF20</citation>) as the
      open standard Bitext format used in the Localization industry. This paper describes how the
      complete open transparent bitext capability of XLIFF can be ported to JSON environments using
      the JLIFF format. We also demonstrate that JLIFF and XLIFF can be used interchangeably,
      effectively allowing to switch between XML and JSON pipelines at will.</para>

</section>

<section xml:id="layoftheland">
    <title>Lay of the land</title>
    <para>The foundational Internationalization Standard is of course <citation>Unicode</citation>
      along with some related Unicode Annexes. But in this paper we are taking the Unicode support
      for granted and will be looking at the domain standards W3C ITS and OASIS XLIFF along with its
      upcoming JSON serialization JLIFF that are the open standards relevant for covering the
      industry process areas outlined in the second part of the <link linkend="intro"
        >Introduction</link>.</para>
    <para>For a long time, XML has been another unchallenged foundation of the multilingual content
      interoperability and hence practically all Localization and Internationalization standards
      started as or became at some point XML vocabularies. Paramount industry wisdom is stored in
      data models that had been developed over decades as XML vocabularies at OASIS, W3C, LISA (RIP)
      and elsewhere. Although ITS is based on <firstterm>abstract metadata categories</firstterm>,
        <citation>ITS 1.0</citation> had only provided specific implementable recommendation for
      XML. The simple yet ingenious idea of ITS is to provide a reusable namespace that can be
      injected into existing formats. Although the notion of a namespace is not confined to XML,
      again ITS 1.0 was only specifically injectable into XML vocabularies.</para>
    <para>
      <citation>ITS20</citation> provides local and global methods for metadata storage not only in
      XML but also in HTML 5, it also looked at mapping into non-XML formats such as
        <citation>NIF</citation>, albeit in a non-normative way. Because native HTML does not
      support the notion of namespaces, ITS 2.0 has to use attributes that are prefixed with the
      string <code>its-</code> for the purpose of being recognized as an HTML 5 module.
        <citation>ITS20</citation> also introduced many new metadata categories compared with
        <citation>ITS10</citation>. ITS 1.0 only looked at metadata in source content that would
      somehow help inform the Internationalization and Localization processes down the line. ITS 2.0
      brought brand new and sometimes complex metadata categories that contain information produced
      during the localization processes or during the language service transformations that are
      necessary to produce target content and are typically facilitated by Bitext. This naturally
      led to a non-normative mapping of <citation>ITS20</citation> to <citation>XLIFF12</citation>
      and to <citation>XLIFF20</citation>. Thus ITS 2.0 became a very useful extension to
      XLIFF.</para>
    <para>One of the main reasons why <citation>XLIFF20</citation> is not backwards compatible with
        <citation>XLIFF12</citation> is that the OASIS XLIFF TC and the wider stakeholder community
      wanted to create XLIFF 2 with a modularized data model. <citation>XLIFF20</citation> has a
      small non-negotiable core but at the same time it brings 8 namespace based modules for
      advanced functionality. The modular and extensible design aims at easy production of "dot"
      revisions or releases of the standard. XLIFF Version 2.0 was intended as the first in the
      future family of backwards compatible XLIFF 2 standards that will share the maximally
      interoperable core (as well as successful modules surviving from 2.0). XLIFF 2 makes a
      distinction between modules and extensions. While module features are optional,
        <firstterm>Conformant XLIFF Agents</firstterm> are bound by an absolute prohibition to
      delete module based metadata (MUST NOT), whereas deletion of extension based data is
      discouraged but not prohibited (the SHOULD NOT normative keyword is used, see
        <citation>BCP14</citation>). The <firstterm>ITS Module</firstterm> is the biggest feature
      that was requested by the industry community and approved by the TC for specification as part
      of <citation>XLIFF21</citation>.</para>
    <para>So in a nutshell the difference between XLIFF 2.1 and XLIFF 2.0 can be explained and
      demonstrated as the two overlapping listings of namespaces.<example>
        <title>Namespaces that appear both in XLIFF 2.1 and XLIFF 2.0</title>
        <programlisting>urn:oasis:names:tc:xliff:document:2.0

urn:oasis:names:tc:xliff:matches:2.0

urn:oasis:names:tc:xliff:glossary:2.0

urn:oasis:names:tc:xliff:fs:2.0

urn:oasis:names:tc:xliff:metadata:2.0

urn:oasis:names:tc:xliff:resourcedata:2.0

urn:oasis:names:tc:xliff:sizerestriction:2.0

urn:oasis:names:tc:xliff:validation:2.0</programlisting>
      </example></para>
    <para>
      <example>
        <title>Namespaces that appear only in XLIFF 2.1</title>
        <programlisting>http://www.w3.org/2005/11/its

urn:oasis:names:tc:xliff:itsm:2.1</programlisting>
      </example>
    </para>
    <para>
      <example>
        <title>Namespaces that appear only in XLIFF 2.0</title>
        <programlisting>urn:oasis:names:tc:xliff:changetracking:2.0</programlisting>
      </example>
    </para>
    <para>Apart from the 11 listed namespaces, both XLIFF Core and the W3C ITS namespace reuse the
        <code>xml</code> namespace. This is still not all namespaces that you can encounter in an
      XLIFF Document. XLIFF 2 Core defines 4 element extension points (<code>&lt;file></code>,
        <code>&lt;skeleton></code>, <code>&lt;group></code>, and <code>&lt;unit></code>) and  4 more
      attribute extension points (<code>&lt;xliff></code>, <code>&lt;note></code>,
        <code>&lt;mrk></code>, and <code>&lt;sm></code>). Most of XLIFF's modules are also
      extensible by elements or by attributes. We will explain in the JLIFF design section how we
      dealt with the inherent multi-namespace character of XLIFF.</para>
    <para>The easiest metadata category to explain the idea of ITS is
        <firstterm>Translate</firstterm>; this is simply a boolean flag that can be used to indicate
      Translatability or not in source content.</para>
  <example>  
  <title>Translate expressed locally in HTML</title>
    <programlisting><![CDATA[<!DOCTYPE html>
<html>
  <head>
    <meta charset=utf-8>
    <title>Translate flag test: Default</title>
  </head>
  <body>
    <p>The <span translate=no>World Wide Web Consortium</span> is
      making the World Wide Web worldwide!</p>
  </body>
</html>]]></programlisting>
  </example>
  <example>  
    <title>Translate expressed locally in XML</title>
    <programlisting><![CDATA[<messages its:version="2.0" xmlns:its="http://www.w3.org/2005/11/its">
  <msg num="123">Click Resume Button on Status Display or <panelmsg its:translate="no"
      >CONTINUE</panelmsg> Button on printer panel</msg>
</messages>]]></programlisting>
  </example>
    <para>Since it is not always practically possible to create local annotations, or the given
      source format or XML vocabulary has elements or attributes with clear semantics with regards
      to some Internationalization data categories such as Translate, in most cases, ITS 2.0 also
      defines a way to express a given data category globally.</para>
    <example>
      <title>Translate expressed globally in XML</title>
      <programlisting><![CDATA[<its:rules version="2.0" xmlns:its="http://www.w3.org/2005/11/its">
  <its:translateRule translate="no" selector="//code"/>
</its:rules>]]></programlisting>
    </example>
    <para>In the above the global <code>its:translateRule</code> indicates that the content of
        <code>&lt;code></code> elements is not to be translated.</para>
    
    <para>XLIFF 2 Core has its own native local method how to express Translatability, it uses the
        <code>xlf:translate</code> attribute. Here and henceforth the prefix <code>xlf:</code>
      indicates this OASIS namespace <code>urn:oasis:names:tc:xliff:document:2.0</code>. Because
      XLIFF is the Bitext format that is used to manage the content structure during the service
      roundtrip in a source format agnostic way, XLIFF needs to make a hard distinction between the
      structural and the inline data. We know the structural vs inline distinction from many XML
      vocabularies and HTML. Some typical structural elements are Docbook <code>&lt;section></code>
      or <code>&lt;para></code> as well as HTML <code>&lt;p></code>. This is how XLIFF 2 will encode
      non-Translatability of a structural element:</para>
  <example>
    <title>XLIFF Core @translate on a structural leaf element</title>
    <programlisting><![CDATA[  <unit id='1' translate="yes">
          <segment>
            <source>Translatable text</source>
          </segment>
  </unit>
  <unit id='2' translate="no">
          <segment>
            <source>Non-translatable text</source>
          </segment>
  </unit>]]></programlisting>
  </example>
  <para>The above could be an <firstterm>Extraction</firstterm> of the following HTML
      snippet:</para>
  <programlisting><![CDATA[       <p translate='yes'>Translatable text</p>
        <p translate='no'>Non-translatable text</p>]]></programlisting>
  
  <para>The same snipped could be also represented like this:</para>
  
  <example>
    <title>XLIFF representing ITS Translate by Extraction behavior w/o explicit metadata</title>
    <programlisting><![CDATA[  <unit id='1'>
          <segment>
            <source>Translatable text</source>
          </segment>
   </unit>]]></programlisting>
  </example>
  <para>However, it is quite likely that the non-translatable structural elements could provide the translators with some critical context information. Hence the non-extraction behavior can only be recommended if the <firstterm>Extracting Agent</firstterm> human or machine can make the call if there is or isn't some sort of contextual or linguistic relationship.</para>
    <para>In case of the Translate metadata category being expressed inline, XLIFF has to use its
        <firstterm>Translate Annotation</firstterm>:</para>
  
  <example>
    <title>XLIFF Core @translate used inline</title>
    <programlisting><![CDATA[  <unit id='1'>
         <segment>
            <source>Text <pc id='1'/><mrk id='m1' translate='no'>Code</mrk></pc></source>
          </segment>
   </unit>]]></programlisting>
  </example>
  
  <para>The above could be an Extraction of the following HTML snippet:</para>
  <programlisting><![CDATA[       <p>Text <code translate='no'>Code</code></p>]]></programlisting>
  
<para>Also inline, there is an option to "hide" the non-translatable content like this:</para>

  <example>
    <title>XLIFF representing ITS Translate by Extraction behavior w/o explicit metadata</title>
    <programlisting><![CDATA[   <unit id='1'>
        <segment>
            <source>Text <ph id='1'/></source>
        </segment>
    </unit> ]]></programlisting>
  </example>
  
  <para>Again not displaying of the non-translatable content can be detrimental to the process, as
      both human and machine translation agents would produce unsuitable translations in case there
      is some linguistic relationship between the displayed translatable text and the content hidden
      by the placeholder code.</para>
    <para>Because XLIFF has its own native method of expressing translatability, generic ITS
      decorators could not succeed. ITS processors can however access the translatability
      information within XLIFF using the following global rule:</para>
  <example>
    <title>ITS global rule to detect translatability in XLIFF</title>
    <programlisting><![CDATA[  <its:rules version="2.0" queryLanguage="xpath">
        <!-- Rules for Translate -->
        <its:translateRule selector="//xlf:*[@translate='no']" translate='no'/>
        <its:translateRule selector="//xlf:*[@translate='yes']" translate='yes'/>
   </its:rules>]]></programlisting>
  </example>


</section>
  
  

<section xml:id="datacats">
    <title>The abstract Localization Interchange Object Model (LIOM) </title>
    <section xml:id="smdatacats">
      <title>The Core Structure</title>
      <para>This <link xl:href="LIOM">figure</link> is a UML class diagram rendering of the abstract
        object model behind XLIFF 2 Core and hence also JLIFF core.</para>
      <para>
        <figure xml:id="LIOM">
          <title>The abstract Localization Interchange Object Model - LIOM</title>
          <mediaobject>
            <imageobject>
              <imagedata fileref='images/Model_LIFF_Class_Diagram.PNG'/>
            </imageobject>
          </mediaobject>
        </figure>
        
      </para>
      <para>The above can be be described as in a natural language as follows:</para>
      <para>A <firstterm>LIOM</firstterm> instance contains at least one file. Each file can contain
        an optional recursive group structure of an arbitrary depth. Because grouping is fully
        optional, files can contain only a flat series of units. But also any file or group can
        contain either a flat structure of units or an array of groups and units (subgroups). Each
        unit contains at least one sub-unit of the type segment (rather than ignorable). Each
        sub-unit contains exactly one source and at most one target. Bitext is designed to represent
        the localizable source structure and only later in the process is expected to be Enriched
        with aligned target content. The content data type can contain character data mixed with
        inline elements. It is worth noting that XLIFF even in its XML serialization only preserves
        a treelike document object model down to unit. In line markup present in the source and
        target content data can form spans that can and often have to overlap the tree structure
        given by the well-formed <code>&lt;mrk></code>, <code>&lt;pc></code>,
          <code>&lt;source></code>, <code>&lt;target></code>, <code>&lt;segment></code>, and
          <code>&lt;ignorable></code> tags.</para>
      <para>The above class diagram shows that a LIOM has four options of logical roots. The
        original XML serialization, i.e. XLIFF 2, can only use the top level root object according
        to its own grammar. On the other hand, the abstract object model caters for use cases where
        LIOM fragments could be exchanged. Such scenarios include real time unit exchange between
        translation tools such as between a <firstterm>Translation Management System
          (TMS)</firstterm> and a translation or review workbench (browser based or standalone), a
        TMS and a <firstterm>Machine Translation (MT)</firstterm> engine, two different TMSes, and
        so on.</para>
      <para>Based on the above, a LIOM instance can represent a number of <firstterm>source
          files</firstterm> intended for Localization. The top level wrapper in the XML
        serialization is the <code>&lt;xliff></code> element, the top level object in the JSON
        serialization is an anonymous to level object with the required <code>jliff</code>
        property.</para>
      <para>
        <example>
          <title>XLIFF top level element</title>
          <programlisting>&lt;xliff xmlns="urn:oasis:names:tc:xliff:document:2.0" 
xmlns:uext1="http://example.com/userextension/1.0"
xmlns:uext2="http://example.com/userextension/2.0"
version="2.1" srcLang="en" trgLang="fr">
  &lt;file … >
    &lt;group … >
      /arbitrary group depth including 0/
      &lt;unit … >
      [ … /truncated payload structure / … ]
      &lt;/unit>
    &lt;/group>
  &lt;file>
&lt;/xliff></programlisting>
        </example>
      </para>
      <para>
        <example>
          <title>JLIFF anonymous top level object</title>
          <programlisting>{
    "jliff": "2.1",
    "@context": {
      "uext1": "http://example.com/userextension/1.0",
      "uext2": "http://example.com/userextension/2.0"
    },
    "srcLang": "en",
    "trgLang": "fr",
    "files | subitems | subunits": [ … /truncated payload structure / … ]      
}</programlisting>
        </example>
      </para>
      <para>Comparing the two examples above, it is clear that XLIFF in its original XML
        serialization doesn't have another legal option but to represent the whole project structure
        of source files. JLIFF has been conceived from the beginning as the JSON Localization
          <emphasis>Fragment</emphasis> Format, so that top level JLIFF object (<code>jliff</code>)
        can wrap an array of files (within the <code>files</code> object), an array of groups or
        units (within the <code>subitems</code> object), or an array of sub-units (within the
          <code>subunits</code> object). </para>
      <para>[NEEDS ADAPTED - left only datacats suitable to demonstrate the point]</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#language-information">Language
          Information</link> uses the <citation>BCP47</citation> data model via
          <code>xml:lang</code> to indicate the natural language of content. This is obviously very
        useful in case you want to source translations or even just render the content with proper
        locale specifics.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#directionality">Directionality</link> has
        quite a profound Internationalization impact, it let's renderers decide at the protocol
        level (as opposed to the plain text or script level) whether the content is to be displayed
        left to right (LTR - Latin script default) or right to left (RTL - Arabic or Hebrew script
        default). But the Unicode Bidirectional Algorithm <citation>UAX #9</citation>as well as
        directionality provisions in HTML and many XML vocabularies changed since 2012/2013, so the
        ITS 2.0 specification text is actually not very helpful here. This obviously doesn't affect
        the importance of the abstract data category and of having proper display behavior for
        bidirectional content.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#preservespace">Preserve Space</link>
        indicates via <code>xml:space</code> whether or not whitespace characters are significant.
        If whitespace is significant in source content it is usually significant also in the target
        content, this is more often then not an internal property of the content format, but it's
        important to keep this characteristics through transformation pipelines. The danger that
        this category is trying to prevent is the loss of significant whitespace characters that
        could not be recovered.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#idvalue">ID Value</link> indicates via
          <code>xml:id</code> a globally unique identifier that should be preserved during
        translation and localization transformations mainly for the purposes of reimport of target
        content to all the right places in the native environment.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#terminology">Terminology</link> can simply
        indicate words or multi-word expressions as terms or non-terms. This is how the category
        worked in ITS 1.0. In ITS 2.0, Terminology can be more useful by pointing to definitions or
        indicating a confidence score, which is especially useful in cases the Terminology entry was
        seeded automatically. Terminology doesn't belong exclusively here. Together with Text
        Analysis it can be actually injected into the content during any stage of the lifecycle and
        is not limited to source. However, it is very important for the localization process, human
        or machine driven, to have Terminology annotated be it even only the simple Boolean
        flag.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#textanalysis">Text Analysis</link> is a
        sister category to Terminology that is new in ITS 2.0. It is intended to hold mostly
        automatically sourced (possibly semi-supervised) entity disambiguation information. This can
        be useful for translators and reviewers but can also enrich reading experience in purely
        monolingual settings.</para>
      <para><link xl:href="">Domain</link> can be used to indicate content topic, specialization or
        subject matter focus that is required to produce certain translations. This can be for
        instance used to select a suitably specialized MT engine, such as one trained on an
        automotive bilingual corpus in case an automotive domain is indicated or. In another use
        case, a language service provider will use a sworn translator and require in country legal
        subject matter review in case the domain was indicated as legal. Although ITS data
        categories are defined independently and don't have implementation dependencies, Domain
        information is well suited for usage together with the Terminology and Text Analysis
        datacats. </para>
    </section>
    <section>
      <title>TBW</title>
      <para>[NEEDS ADAPTED - left only datacats suitable to demonstrate the point]</para>
      <para>It might seem that this type of metadata is completely new in <citation>ITS
          2.0</citation>, since <citation>ITS 1.0</citation> concentrated almost exclusively on
        source metadata. However, as mentioned above, Terminology - that was present in already in
        ITS 1.0 - can be injected at any point and is not confined to source. Also Directionality is
        a characteristics of source as well as target and has profound importance during the
        roundtrip. This was however not the focus in ITS 1.0. </para>
      <para>
        <link xl:href="http://www.w3.org/TR/its20/#mtconfidence">MT Confidence</link>, <link
          xl:href="http://www.w3.org/TR/its20/#lqissue">Localization Quality Issue</link>, <link
          xl:href="http://www.w3.org/TR/its20/#lqrating">Localization Quality Rating</link>, and
          <link xl:href="http://www.w3.org/TR/its20/#provenance">Provenance</link> - all new
        categories in ITS 2.0 - can be only produced during Localization transformations;
        specifically, during Machine Translation, during a review or quality assurance process,
        during or immediately after a manual or automated translation or revision.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#mtconfidence">MT Confidence</link> gives a
        simple score between 0 and 1 that encodes the automated translation system's internal
        confidence that the produced translation is correct. This score isn't interoperable but can
        be used in single engine scenarios for instance to color code the translations for readers
        or post-editors. It can also be used for storing the data for several engines and running
        comparative studies to make the score interoperable first in specific environments and later
        on maybe generally. </para>
      <para><link xl:href="http://www.w3.org/TR/its20/#lqissue">Localization Quality Issue</link>
        contains a taxonomy of possible Translation and Localization errors that can be applied in
        annotations of arbitrary content spans. The taxonomy ensures that this information can be
        exchanged among various Localization roundtrip agents. Although this mark up is typically
        introduced in a Bitext environment on target spans, marking up source isn't exclude and can
        be very practical, especially when implementing the feedback or even reporting a source
        issue. Importantly, the issues and their descriptions can be Extracted into target content
        and consumed by monolingual reviewers in the native environment.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#lqrating">Localization Quality Rating</link>
        is again a simple score that gives a percentage indicating the quality of any portion of
        content. This score is obviously only interoperable within an indicated Localization Quality
        Rating system or metrics. Typically flawless quality is considered 100 % and various issue
        rates per translated volume would strike down percentages, possibly dropping under an
        acceptance threshold that can be also specified.</para>
      <para><link xl:href="http://www.w3.org/TR/its20/#provenance">Provenance</link> in ITS is
        strictly specialized to indicate only translation and revision agents. Agents can be
        organizations, people or tools or described by combinations of those. For instance,
        Provenance can indicate that the Reviser John Doe from ACME Language Quality Assurance Inc.
        produced a content revision with the Perfect Cloud Revision Tool. </para>
    
 
    <para>In spite of <citation>XLIFF 2.1</citation> now using the W3C namespace for the ITS Module,
        there is a systematic scope mismatch between the XLIFF defined ITS attributes and the ITS
        defined XML attributes. Because ITS 2.0 has no provision to parse pseudo-spans, it will
        necessarily fail to identify spans formed by XLIFF Core <code>&lt;sm/></code> and
          <code>&lt;em/></code> markers.</para>
    <para>In XLIFF, Modifiers can always transform <code>&lt;mrk id="1">span of text&lt;/mrk></code>
        into <code> &lt;sm id="1"/>span of text &lt;em startRef="1"/></code>, which is fundamentally
        inaccessible by ITS Processors without extended provisions. Unmodified or unextended ITS
        Rules will find the <code>&lt;sm/></code> nodes, if those nodes do hold the W3C ITS
        namespace based attributes or native XLIFF attributes that can be globally pointed to by ITS
        rules, yet they will fail to identify the pseudo-spans and will consider the
          <code>&lt;sm/></code> nodes empty, ultimately failing to identify the proper scope of the
        correctly identified datacat. XLIFF implementers who want to make their XLIFF Stores
        maximally accessible to ITS processors are encouraged to avoid forming of
          <code>&lt;sm/></code> based spans, it is however often not possible. Had it been possible,
        XLIFF would have not needed to define <code>&lt;sm/></code> and <code>&lt;em/></code>
        delimited pseudo-spans in the first place. </para>
    <para>Principal reasons to form pseudospans include the following requirements: 1) capability to
      represent non-XML content, 2) need for overlapping annotations, 3) capability to represent
      annotations overlapping with formatting spans as well as 4) annotations broken by segmentation
      (which has to be represented as well formed structural albeit transient nodes).</para>
  </section>
</section>

<section>
<title>The design of JLIFF</title>
    <para>The design of JLIFF follows the design of XLIFF 2 closely. As with XLIFF 2, the JLIFF 2
      Core is the abstract Localization Interchange Object Model - LIOM. One of the primary goals of
      JLIFF 2 is compatibility with XLIFF 2. While JLIFF is structurally different compared to XLIFF
      2 due to the much simpler JSON representation format, compatibility is made possible through
      the following mappings:</para>
  <orderedlist>
    <listitem>
     <para>As a general rule, JSON object property names are used to represent XLIFF elements and
      attributes, with the exception of element sequences that must be represented by JSON arrays.
      JSON object properties should be unique and are unordered, whereas these constraints are not
      generally imposed on XML elements; </para></listitem><listitem>
        
      
    <para>It was decided to use JSON arrays to represent element sequences, for example a
      sequence of <code>&lt;file></code> elements becomes an array identified by the JSON object
      property <code>"files": […]</code> where each array item is an anonymous file object that may
      contain an array of <code>"subfiles": […]</code>. It was decided to use plural forms to refer
      to arrays in JLIFF and as a reminder of the structual differences with XLIFF;</para></listitem><listitem>
        
      
    <para>To store units and groups of files, JSON object property <code>"subfiles": […]</code>
      is an array of unit and group objects representing XLIFF <code>&lt;unit></code> and
        <code>&lt;group></code> elements, where an anonymous unit object is identified by a
        <code>"kind": "unit"</code> and an anonymous group object is identified by <code>"kind":
          "group"</code>;</para></listitem>
   <listitem>
     
    <para>Likewise, <code>"subunits": […]</code> is an array of subunits of a unit object, where a
          segment subunit is identified as an object with <code>"kind": "segment"</code> and a
          ignorable object is identified by <code>"kind": "ignorable"</code>;</para></listitem>
      <listitem>
    <para>A subset of XSD types that are used in XLIFF are also adopted in the JLIFF schema by
      defining corresponding JSON schema string types with restricted value spaces defined by regex
      patterns for <code>NCName</code>, <code>NMTOKEN</code>, <code>NMTOKENS</code>, and
        <code>URI/IRI</code>. The latter is not restricted by a regex pattern due to the lax
      validation of URI and IRI values by processors;</para></listitem>
      <listitem><para>Because JSON intrinsically lacks namespace support, it was decided to use qualified
      JSON object property names to represent XLIFF modules, which is purely syntactic to enhance
      JLIFF document readability and processing. For example, ITS module properties are identified
      by prefix <code>its_</code>, such as <code>"its_locQualityIssues"</code>;</para></listitem>
      <listitem>
    <para>JLIFF extensions are defined by the optional JSON-LD context <code>"@context":
        {…}</code> as a property of the anonymous JLIFF root object. JSON-LD offers a suitable
      replacement of XML namespaces required for extension identification and processing. A JSON-LD
      context is a mapping of prefixes to IRIs. A JSON-LD processor resolves the prefix in an object
      property name to a fully qualified name with corresponding IRI qualifier;</para></listitem>
      
      <listitem>
    <para>To identify JLIFF documents, the anonymous JLIFF root object has property
      <code>"jliff": "2.0"</code> or <code>"jliff": "2.1"</code>;</para>
      </listitem>
      <listitem>
    <para>One of the decisions taken in relation to element mappings was not to explicitly
      support XLIFF <code>&lt;pc/></code> and <code>&lt;mrk/></code> elements, therefore it was
      decided that <code>&lt;mrk/></code> is mapped to <code>&lt;sm/></code> and         <code>&lt;em/></code> pairs, and <code>&lt;pc/></code> is mapped to <code>&lt;sc/></code>
 and <code>&lt;ec/></code>      pairs.</para></listitem>
  </orderedlist>

</section>

<section>
	<title>Reference Implementation</title>
	<para>It was an early goal to work on a concrete implementation of JLIFF in parallel to the
      development of the schema. It would give us an early opportunity to find and work through any
      design flaws or limitations. Fortunately, the <citation>JliffGraphTools</citation>  (JGT)
      reference implementation has been open source since early on.</para><para>It was a 
	wish that JLIFF should be easy to implement and serialize/deserialize 
	using well-known Json libraries.</para><para>Another noticeable difference in the structure of JLIFF and XLIFF is inline markup. In XLIFF
      inline markup is nested within the segment text as child elements of the
        <code>&lt;segment/></code> elements. In JLIFF the segment text and inline markup are stored
      as an array of objects property of the Unit's source and target properties. MAYBE ADD SOME
      EXAMPLES. This has an impact on how rendering tools may display strings for translation, see
      below on the approach taken in JGT.</para><para>Having got the priority of JSON serialization and deserialization working we then looked at
      roundtripping. JliffGraphTools supports bidirectional serialization between XLIFF and JLIFF
      and it is this library which powers the <citation>Xliff2Jliff</citation> web application made
        public at <link xl:href="http://xliff2jliff.azurewebsites.net/">http://xliff2jliff.azurewebsites.net/</link>.</para><para>At present when segments for translation are rendered in JGT, there is an option to flatten
      the array of text and inline markup objects and render them in a way which is based upon the
      approach taken in the <citation>Okapi Framework</citation> XLIFF library. That is inline
      markup tags are converted to coded text which uses characters from the private use area of
      Unicode to delimit inline markup tags. (see
      http://okapiframework.org/devguide/gettingstarted.html#textUnits).</para>
</section>

  <section>
    <title>Conclusions</title>
    <para>In the above we tried to show how we ported into JSON XLIFF 2, a complex business
      vocabulary from the area of Translation and Localization. While the paper deals in detail only
      with XLIFF and JLIFF, we believe that important topics were covered that will be useful for
      designer who will endeavor porting their own specialized multi-namespace business vocabularies
      into JSON.</para>
    <para>The major takeway we'd like to suggest is not to port directly from XML to JSON. It is
      worth the time to start your exercise with expressing your XML data model in an abstract way,
      we used UML class diagram as the serialization independent abstract method.</para>
    <para>XML serializations are as a rule fraught with "XMLism" or "SGMLism". While some of the XML
      capabilities such as the multi-namespace support are clear XML advantages that will force the
      JSON-equivalent-designer into complex and more or less elegant workarounds and compromises.
      Some other XML traits and constraints are arbitrary from the point of view of other languages
      and serialization methods.</para>
    <para>To name just a few examples of XMLism that doesn't need maintained in JSON. You don't need
      to support well formed versions of inline markup in JSON, it is easier to serialize everything
      linearly. In JSON, all payload space is significant, so you don't need to keep the
        <code>preserve</code> | <code>default</code> flag in your JSON serialization. Instead make
      sure that all inline data is normalized and set to <code>preserve</code> in your XML data.
      JSON data types are much poorer than XML datatyes, nevertheless, you can make up for this with
      relative ease with the usage of regular expression patterns in your JSON schema. For
      instance</para>
    <para><example>
        <title>NCName pattern in JSON schema</title>
      <programlisting>"NCName": {
      "description": "XSD NCName type for xml:id interoperability",
      "type": "string",
      "pattern": "^[_A-Za-z][-._A-Za-z0-9]*$"
    }</programlisting></example></para>
    <para>Namespaces
      support workarounds in JSON are worth an extra mention. While JSON doesn't support namespaces
        <emphasis>per se</emphasis>. We identified the JSON-LD methods for introducing and
      shortening fully qualified names quite useful as a namespaces support surrogate. For practical
      reasons (like prevention of hammering of OASIS servers to read XLIFF module context files) we
      decided to use the full blown JSON-LD method for expanding prefixes into fully qualified names
      only for extensions. We decided to use an arbitrary "_" (underscore) prefix separator to make
      the XLIFF modules human discernable. There goes the disadvantage of losing the modularity of
      XLIFF modules in JLIFF, yet we felt that JSON-LD-coding of each of the modules data would be
      very oblique and heavyweight with minor benefits to outweigh the drawbacks.</para>
  </section>

<bibliography xml:id="references">

  <bibliomixed><abbrev>1</abbrev> S. Saadatfar and D. Filip: <title>Advanced Validation Techniques
        for XLIFF 2</title>. in Localisation Focus, vol. 14, no. 1, pp. 43-50, April 2015.
          <bibliomisc><link xl:href="http://www.localisation.ie/locfocus/issues/14/1"/></bibliomisc>
    </bibliomixed>
  <bibliomixed><abbrev>2</abbrev> S. Saadatfar and D. Filip: <title>Best Practice for DSDL-based
    Validation</title>. in XML London 2016 Conference Proceedings, May 2016. <bibliomisc><link xl:href="https://xmllondon.com/2016/xmllondon-2016-proceedings.pdf#page=64"></link></bibliomisc></bibliomixed>
    
  <bibliomixed><abbrev>3</abbrev> D. Filip, <title>W3C ITS 2.0 in OASIS XLIFF 2.1</title>, in XML
    Prague 2017 - Conference Proceedings, Prague, 2017, vol. 2017, pp. 55–71. <bibliomisc xl:href="http://archive.xmlprague.cz/2017/files/xmlprague-2017-proceedings.pdf#page=67"><link></link></bibliomisc></bibliomixed>
   
  <bibliomixed><abbrev>BCP14</abbrev> S. Bradner and B. Leiba, Eds. <title>Key words for use in RFCs
        to Indicate Requirement Levels and Ambiguity of Uppercase vs Lowercase in RFC 2119 Key
        Words</title>, IETF (Internet Engineering Task Force) 1997 &amp; 2017 <bibliomisc>
        <link xl:href="http://tools.ietf.org/html/bcp14">http://tools.ietf.org/html/bcp14</link>
      </bibliomisc> .</bibliomixed>
  
  <bibliomixed><abbrev>BCP47</abbrev> M. Davis, Ed. <title>Tags for Identifying Languages</title>,
        <bibliomisc> IETF (Internet Engineering Task Force) <link
          xl:href="http://tools.ietf.org/html/bcp47">http://tools.ietf.org/html/bcp47</link>
      </bibliomisc>.</bibliomixed>
  
  
  <bibliomixed><abbrev>ITS10</abbrev> C. Lieske and F. Sasaki, Eds.: <title>Internationalization Tag
        Set (ITS) Version 1.0</title>. W3C Recommendation, 03 April 2007. W3C. <bibliomisc><link
          xl:href="https://www.w3.org/TR/its/"/></bibliomisc>
    </bibliomixed>
  
  <bibliomixed><abbrev>ITS20</abbrev> D. Filip, S. McCance, D. Lewis, C. Lieske, A. Lommel, J.
      Kosek, F. Sasaki, Y. Savourel, Eds.: <title>Internationalization Tag Set (ITS) Version
        2.0</title>. W3C Recommendation, 29 October 2013. W3C. <bibliomisc><link
          xl:href="http://www.w3.org/TR/its20/"/></bibliomisc>
    </bibliomixed>
  <bibliomixed><abbrev>L10nStandards</abbrev> D. Filip: Localization Standards Reader 4.0 [v4.0.1], Multilingual, vol. 30, no. 1, pp. 59–73, Jan/Feb-2019. <bibliomisc><link>https://magazine.multilingual.com/issue/jan-feb-2019dm/localization-standards-reader-4-0/</link></bibliomisc>
  </bibliomixed>
  
  <bibliomixed><abbrev>NIF</abbrev> S. Hellmann, J. Lehmann, S. Auer, and M. Brümmer:
    <title>Integrating NLP using Linked Data</title>. 12th International Semantic Web
    Conference, Sydney, Australia, 2013. <bibliomisc><link
      xl:href="http://svn.aksw.org/papers/2013/ISWC_NIF/public.pdf"/></bibliomisc>
  </bibliomixed>
  
  <bibliomixed><abbrev>UAX9</abbrev> M. Davis, A. Lanin, and A. Glass, Eds.: <title>UAX #9: Unicode
        Bidirectional Algorithm.</title>. Version: Unicode 11.0.0, Revision 39, 09 May 2018. Unicode
      Consortium. <bibliomisc><link xl:href="http://www.unicode.org/reports/tr9/tr9-39.html"
        /></bibliomisc>
    </bibliomixed>  
  
  <bibliomixed><abbrev>Unicode</abbrev> K. Whistler et al., Eds.: <title>The Unicode
        Standard</title>. Version 11.0 - Core Specification, 05 June 2018. Unicode Consortium.
          <bibliomisc><link
          xl:href="https://www.unicode.org/versions/Unicode11.0.0/UnicodeStandard-11.0.pdf"
        /></bibliomisc>
    </bibliomixed>

  <bibliomixed><abbrev>XLIFF12</abbrev> Y. Savourel, J. Reid, T. Jewtushenko, and R. M. Raya, Eds.:
      XLIFF Version 1.2, OASIS Standard. OASIS, 2008. Y. Savourel, D. Filip, R. M. Raya, and Y.
      Savourel, Eds.: <title>XLIFF Version 1.2</title>. OASIS Standard, 01 February 2008. OASIS.
          <bibliomisc><link xl:href="http://docs.oasis-open.org/xliff/v1.2/os/xliff-core.html"
        /></bibliomisc>
    </bibliomixed>
  
  <bibliomixed><abbrev>XLIFF20</abbrev> T. Comerford, D. Filip, R. M. Raya, and Y. Savourel, Eds.:
        <title>XLIFF Version 2.0</title>. OASIS Standard, 05 August 2014. OASIS. <bibliomisc><link
          xl:href="http://docs.oasis-open.org/xliff/xliff-core/v2.0/os/xliff-core-v2.0-os.html"
        /></bibliomisc>
    </bibliomixed>

<bibliomixed><abbrev>XLIFF21</abbrev> D. Filip, T. Comerford, S. Saadatfar, F. Sasaki, and Y.
      Savourel, Eds.: <title>XLIFF Version 2.1</title>. OASIS Standard, 13 February 2018. OASIS
          <bibliomisc><link
            xl:href="http://docs.oasis-open.org/xliff/xliff-core/v2.1/os/xliff-core-v2.1-os.html"
        /></bibliomisc>
    </bibliomixed>

  <bibliomixed><abbrev>XLIFF21prd02</abbrev> D. Filip, T. Comerford, S. Saadatfar, F. Sasaki, and Y.
      Savourel, Eds.: <title>XLIFF Version 2.1</title>. Public Review Draft 02, February 2017. OASIS
          <bibliomisc><link
          xl:href="http://docs.oasis-open.org/xliff/xliff-core/v2.1/csprd02/xliff-core-v2.1-csprd02.html"
        /></bibliomisc>
    </bibliomixed>
  

</bibliography>

</article>
